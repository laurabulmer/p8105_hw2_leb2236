P8105 HW2
================
Laura Bulmer
2024-10-02

## Problem 1

First I am going to import and then read/clean the NYC Transit data.

``` r
transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor :: clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
transit_data
```

    ## # A tibble: 1,868 × 20
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 13 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <chr>, route9 <chr>, route10 <chr>, route11 <chr>, entry <lgl>,
    ## #   exit_only <chr>, vending <chr>, entrance_type <chr>, ada <lgl>

The next bit of code selects the station name and line, and uses
distinct() command to obtain all unique combinations.

``` r
transit_data |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

The next bit of code is similar but filters according to ADA compliance.

``` r
transit_data |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

The next bit of code is used to determine the proportion of stations
without vending that allow entrance.

``` r
transit_data |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. We convert the
data from wide to long format. Then we filter on A train and on ADA
compliance, and use select() and distinct() to obstain dataframes with
the required stations in rows.

``` r
transit_data |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

``` r
transit_data |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

## Problem \#2

First, we are going to import the Mr. Trash Wheel dataset. Then we read
and clean it.

``` r
mr_trash_wheel = 
  readxl :: read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = 1, range = "A2:N586") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(trash_wheel = "Mr. Trash Wheel") %>% 
  relocate(trash_wheel)
```

Then we will do the same thing for the Professor Trash Wheel and Gwynnda
datasets.

``` r
prof_trash_wheel = 
  readxl :: read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = 2, range = "A2:M108") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(trash_wheel = "Prof. Trash Wheel") %>% 
  mutate(year =as.character(year)) %>% 
  relocate(trash_wheel)

gwynnda_wheel = 
  readxl :: read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                       sheet = 4, range = "A2:L158") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(trash_wheel = "Gwynnda Trash Wheel") %>% 
  mutate(year =as.character(year)) %>% 
  relocate(trash_wheel)
```

``` r
mr_trash_wheel
```

    ## # A tibble: 584 × 15
    ##    trash_wheel     dumpster month year  date                weight_tons
    ##    <chr>              <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
prof_trash_wheel
```

    ## # A tibble: 105 × 14
    ##    trash_wheel       dumpster month    year  date                weight_tons
    ##    <chr>                <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 Prof. Trash Wheel        1 January  2017  2017-01-02 00:00:00        1.79
    ##  2 Prof. Trash Wheel        2 January  2017  2017-01-30 00:00:00        1.58
    ##  3 Prof. Trash Wheel        3 February 2017  2017-02-26 00:00:00        2.32
    ##  4 Prof. Trash Wheel        4 February 2017  2017-02-26 00:00:00        3.72
    ##  5 Prof. Trash Wheel        5 February 2017  2017-02-28 00:00:00        1.45
    ##  6 Prof. Trash Wheel        6 March    2017  2017-03-30 00:00:00        1.71
    ##  7 Prof. Trash Wheel        7 April    2017  2017-04-01 00:00:00        1.82
    ##  8 Prof. Trash Wheel        8 April    2017  2017-04-20 00:00:00        2.37
    ##  9 Prof. Trash Wheel        9 May      2017  2017-05-10 00:00:00        2.64
    ## 10 Prof. Trash Wheel       10 May      2017  2017-05-26 00:00:00        2.78
    ## # ℹ 95 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>

``` r
gwynnda_wheel
```

    ## # A tibble: 39 × 13
    ##    trash_wheel         dumpster month    year  date                weight_tons
    ##    <chr>                  <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 Gwynnda Trash Wheel      117 November 2022  2022-11-03 00:00:00        3.06
    ##  2 Gwynnda Trash Wheel      118 November 2022  2022-11-15 00:00:00        3   
    ##  3 Gwynnda Trash Wheel      119 November 2022  2022-11-19 00:00:00        2.42
    ##  4 Gwynnda Trash Wheel      120 November 2022  2022-11-22 00:00:00        2.37
    ##  5 Gwynnda Trash Wheel      121 November 2022  2022-11-30 00:00:00        2.91
    ##  6 Gwynnda Trash Wheel      122 December 2022  2022-12-13 00:00:00        2.35
    ##  7 Gwynnda Trash Wheel      123 December 2022  2022-12-17 00:00:00        2.8 
    ##  8 Gwynnda Trash Wheel      124 December 2022  2022-12-17 00:00:00        2.69
    ##  9 Gwynnda Trash Wheel      125 December 2022  2022-12-19 00:00:00        2.27
    ## 10 Gwynnda Trash Wheel      126 December 2022  2022-12-19 00:00:00        2.5 
    ## # ℹ 29 more rows
    ## # ℹ 7 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

Next, we will merge the three datasets into one by the trash_wheel
variable.

``` r
trash_wheel_df = bind_rows(mr_trash_wheel, prof_trash_wheel,gwynnda_wheel)
```
